{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Approach Vector Store"
      ],
      "metadata": {
        "id": "512BFFleAC73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-ZD8_pM9-pC",
        "outputId": "99d253da-fc42-4041-b989-6d2285b01fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed faiss-cpu-1.8.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QGd1gaXAlRw",
        "outputId": "88e6888b-37aa-4daa-fa06-9520f9bf20dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.18 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 30.1/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgAoRWYK9WkA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Load YOLOv5 model\n",
        "yolo_model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define a transformation pipeline\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def detect_and_crop(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Detect objects in the image\n",
        "    results = yolo_model(image_np)\n",
        "    boxes = results[0].boxes.xyxy  # Get bounding boxes\n",
        "\n",
        "    if len(boxes) > 0:\n",
        "        # Take the first detected object for cropping\n",
        "        x1, y1, x2, y2 = map(int, boxes[0])\n",
        "        image = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "    return image\n",
        "\n",
        "def extract_features(image_path):\n",
        "    image = detect_and_crop(image_path)\n",
        "    image = preprocess(image)\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        features = model(image)\n",
        "\n",
        "    return features.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "image_paths = ['/content/Data analyst operation-MuhFaridanSutariya.jpg', '/content/messi 1.jpeg', '/content/foto mantap.jpg', '/content/209105611_503055027473834_75509644885757551_n.jpg']\n",
        "\n",
        "feature_vectors = [extract_features(image_path) for image_path in image_paths]\n",
        "\n",
        "features = np.vstack(feature_vectors).astype(np.float32)\n",
        "\n",
        "# Create FAISS index\n",
        "d = features.shape[1]  # dimension of feature vectors\n",
        "index = faiss.IndexFlatL2(d)\n",
        "\n",
        "index.add(features)\n",
        "\n",
        "# Save the index\n",
        "faiss.write_index(index, 'image_index.faiss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0JVJBNX9jN7",
        "outputId": "edc0cca7-601d-4f3c-ed75-6777ec7d73c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x480 1 person, 86.8ms\n",
            "Speed: 33.0ms preprocess, 86.8ms inference, 711.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 12.3ms\n",
            "Speed: 4.5ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x640 1 person, 2 dining tables, 1 cell phone, 17.3ms\n",
            "Speed: 4.4ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 16.8ms\n",
            "Speed: 4.4ms preprocess, 16.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def search_similar_images(query_image_path, index, k=1):\n",
        "    query_features = extract_features(query_image_path).astype(np.float32)\n",
        "\n",
        "    D, I = index.search(query_features, k)\n",
        "\n",
        "    return I\n",
        "\n",
        "index = faiss.read_index('image_index.faiss')\n",
        "\n",
        "query_image_path = '/content/2111130 MUHAMMAD FARIDAN SUTARIYA.JPG'\n",
        "\n",
        "similar_image_indices = search_similar_images(query_image_path, index)\n",
        "\n",
        "print(similar_image_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTEU0bPr-Inw",
        "outputId": "06aab1d5-d07b-47f3-b196-3a9ef1c69d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 448x640 1 person, 64.1ms\n",
            "Speed: 4.8ms preprocess, 64.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "[[0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_image_paths = [image_paths[i] for i in similar_image_indices[0]]\n",
        "\n",
        "print(\"Similar images:\")\n",
        "for path in similar_image_paths:\n",
        "    print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cpzNjA3-V6k",
        "outputId": "fea2bec4-b891-44eb-d8a2-fc07c8312ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar images:\n",
            "/content/Data analyst operation-MuhFaridanSutariya.jpg\n"
          ]
        }
      ]
    }
  ]
}